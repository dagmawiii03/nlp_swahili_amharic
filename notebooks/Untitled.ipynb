{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e40f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing essential modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d7a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing local modules\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "\n",
    "from clean import Clean\n",
    "from utils import vocab\n",
    "from deep_learner import DeepLearn\n",
    "from modeling import Modeler\n",
    "from evaluator import CallbackEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987abe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping an object\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52777c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "AM_ALPHABET='ሀለሐመሠረሰቀበግዕዝተኀነአከወዐዘየደገጠጰጸፀፈፐቈኈጐኰፙፘፚauiāeəo'\n",
    "EN_ALPHABET='abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1d97da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 19:38:32,213:logger:Successfully initialized clean class\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'ሀ', 'ለ', 'ሐ', 'መ', 'ሠ', 'ረ', 'ሰ', 'ቀ', 'በ', 'ግ', 'ዕ', 'ዝ', 'ተ', 'ኀ', 'ነ', 'አ', 'ከ', 'ወ', 'ዐ', 'ዘ', 'የ', 'ደ', 'ገ', 'ጠ', 'ጰ', 'ጸ', 'ፀ', 'ፈ', 'ፐ', 'ቈ', 'ኈ', 'ጐ', 'ኰ', 'ፙ', 'ፘ', 'ፚ', 'a', 'u', 'i', 'ā', 'e', 'ə', 'o'] (size =44)\n"
     ]
    }
   ],
   "source": [
    "#create cleaner object to numerate every amharic alphabets\n",
    "cleaner = Clean()\n",
    "char_to_num,num_to_char=vocab(AM_ALPHABET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bdf6c",
   "metadata": {},
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a48d87e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv of each dataset into their respective dataframes\n",
    "swahili_df = pd.read_csv('../data/swahili.csv')\n",
    "lang = pd.read_csv(\"../data/swahili.csv\")\n",
    "lang['type']='swahili'\n",
    "\n",
    "amharic_df = pd.read_csv(\"../data/amharic.csv\")\n",
    "amharic_df['type']='amharic'\n",
    "language_df = lang.append(amharic_df, ignore_index=True) #used to append two datasets and combine them in to a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde18f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of modeler class\n",
    "pre_model = Modeler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a4810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
